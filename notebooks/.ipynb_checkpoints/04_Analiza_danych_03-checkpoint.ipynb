{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Opis notatnika\n",
    " Zmierzamy do końca analizy danych, które zostały nam udostępnione. Ten krok dodaje jeszcze więcej informacji do naszego wyjściowego zbioru. Tym razem sprawdzimy między innymi to, czy opóźnienia lotów zależne są od trasy czy warunków pogodowych.\n",
    "\n",
    " Zanim jednak do tego przejdziemy, należy, podobnie jak w poprzednich krokach, skonfigurować odpowiednio notatnik.\n",
    " \n",
    " W tej części warsztatu ponownie wcielasz się w rolę Analiyka Danych, którego zadaniem jest wykonanie analizy eksplotacyjnej zbioru danych - jedno z wymagań dostarczonych przez klienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj zaimportuj wymagane biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from psycopg2 import connect\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL\n",
    "import plotly.express as px\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Połączenie z bazą danych\n",
    " Tutaj uzupełnij konfigurację połączenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = 'postgres'\n",
    "password = '123188523'\n",
    "\n",
    "host = 'localhost'\n",
    "database = 'airlines'\n",
    "port = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj stwórz zmienną engine, która zostanie użyta do połączenia z bazą danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = URL.create(\n",
    "    \"postgresql\",\n",
    "    username = 'postgres',\n",
    "    password = '123188523',\n",
    "    host = 'localhost',\n",
    "    database = 'airlines')\n",
    "    \n",
    "engine = create_engine(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj uzupełnij implementację metody `read_sql_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_table_from_db(table_name):\n",
    "    table_data = pd.read_sql_table(table_name, \n",
    "                             con=engine, \n",
    "                             index_col=None, \n",
    "                             coerce_float=True, \n",
    "                             parse_dates=None, \n",
    "                             columns=None, \n",
    "                             chunksize=None) #if chunksize is set it returns a generator object, not a df\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj zaczytaj zapisaną wcześniej ramkę danych `flight_df` do zmniennej o takiej samej nazwie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1057391, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df = pd.read_csv(r'..\\data\\processed\\flight_df_02.csv')\n",
    "flight_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Wzbogacenie o `airport_list`\n",
    " Wczytaj do obszaru roboczego tabelę `airport_list` używając procedury `read_sql_table`. Wykonaj poniższe ćwiczenia:  \n",
    " 1. Sprawdź, czy klucz `origin_airport_id` jest unikalny, tj. nie ma dwóch takich samych wartości w kolumnie `origin_airport_id`.  \n",
    " 1. Jeżeli duplikaty występują, usuń je w najdogodniejszy dla Ciebie sposób.  \n",
    " 1. Jeśli duplikaty nie występują, złącz ramki `airport_list_df` wraz z aktualną `flight_df`, używając kolumny `origin_airport_id` oraz złączenia typu `LEFT JOIN`. Z ramki `airport_list_df` interesuje nas dodanie kolumny `origin_city_name`.  \n",
    " 1. Dodatkowo dokonaj jeszcze raz złączenia ramki `flight_df` z `airport_list_df`, tym razem jednak złącz kolumnę `destination_airport_id` wraz z `origin_airport_id`. Podobnie jak wcześniej, interesuje nas kolumna `origin_city_name`, jedank ona powinna zostać wyświetlona jako `destination_city_name`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj wczytaj ramkę `airport_list_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>display_airport_name</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11638</td>\n",
       "      <td>Fresno Air Terminal</td>\n",
       "      <td>Fresno, CA</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13342</td>\n",
       "      <td>General Mitchell Field</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>MILWAUKEE MITCHELL AIRPORT, WI US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13244</td>\n",
       "      <td>Memphis International</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>MEMPHIS INTERNATIONAL AIRPORT, TN US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15096</td>\n",
       "      <td>Syracuse Hancock International</td>\n",
       "      <td>Syracuse, NY</td>\n",
       "      <td>SYRACUSE HANCOCK INTERNATIONAL AIRPORT, NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10397</td>\n",
       "      <td>Atlanta Municipal</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  origin_airport_id            display_airport_name origin_city_name  \\\n",
       "0   0              11638             Fresno Air Terminal       Fresno, CA   \n",
       "1   1              13342          General Mitchell Field    Milwaukee, WI   \n",
       "2   2              13244           Memphis International      Memphis, TN   \n",
       "3   3              15096  Syracuse Hancock International     Syracuse, NY   \n",
       "4   4              10397               Atlanta Municipal      Atlanta, GA   \n",
       "\n",
       "                                                name  \n",
       "0               FRESNO YOSEMITE INTERNATIONAL, CA US  \n",
       "1                  MILWAUKEE MITCHELL AIRPORT, WI US  \n",
       "2               MEMPHIS INTERNATIONAL AIRPORT, TN US  \n",
       "3      SYRACUSE HANCOCK INTERNATIONAL AIRPORT, NY US  \n",
       "4  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_list_df = load_table_from_db('airport_list')\n",
    "airport_list_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj sprawdż, czy występują duplikaty dla kolumny `origin_airport_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = airport_list_df.duplicated(subset='origin_airport_id').sum()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj usuń duplikaty – jeśli występują"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nie występują"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj dokonaj złączenia ramki `flight_df` oraz `airport_list_df` używając `origin_airport_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'month', 'day_of_month', 'day_of_week', 'op_unique_carrier',\n",
       "       'tail_num', 'op_carrier_fl_num', 'origin_airport_id', 'dest_airport_id',\n",
       "       'crs_dep_time', 'dep_time', 'dep_delay', 'dep_time_blk', 'crs_arr_time',\n",
       "       'arr_time', 'arr_delay_new', 'arr_time_blk', 'cancelled',\n",
       "       'crs_elapsed_time', 'actual_elapsed_time', 'distance', 'distance_group',\n",
       "       'carrier_delay', 'weather_delay', 'nas_delay', 'security_delay',\n",
       "       'late_aircraft_delay', 'year', 'is_delayed', 'is_weekend',\n",
       "       'distance_agg', 'manufacture_year', 'origin_city_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# złącz ramki airport_list_df wraz z aktualną flight_df, \n",
    "# używając kolumny origin_airport_id oraz złączenia typu LEFT JOIN. \n",
    "# Z ramki airport_list_df interesuje nas dodanie kolumny origin_city_name.\n",
    "\n",
    "tmp_flight_df = pd.merge(flight_df, airport_list_df[['origin_airport_id', 'origin_city_name']], on='origin_airport_id', how='left')\n",
    "tmp_flight_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj dokonaj złączenia ramki `flight_df` oraz `airport_list_df` używając `destination_airport_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>year</th>\n",
       "      <th>is_delayed</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>distance_agg</th>\n",
       "      <th>manufacture_year</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>destination_city_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3752</td>\n",
       "      <td>1901</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1548</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3752</td>\n",
       "      <td>2020</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N282AK</td>\n",
       "      <td>52</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1450</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N307AS</td>\n",
       "      <td>88</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N318AS</td>\n",
       "      <td>92</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1305</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057386</th>\n",
       "      <td>1384259</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>WN</td>\n",
       "      <td>N413WN</td>\n",
       "      <td>225</td>\n",
       "      <td>15304</td>\n",
       "      <td>10397</td>\n",
       "      <td>1005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(400, 500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057387</th>\n",
       "      <td>1384260</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>WN</td>\n",
       "      <td>N742SW</td>\n",
       "      <td>758</td>\n",
       "      <td>15304</td>\n",
       "      <td>10397</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>(400, 500]</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057388</th>\n",
       "      <td>1384261</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>WN</td>\n",
       "      <td>N774SW</td>\n",
       "      <td>877</td>\n",
       "      <td>15304</td>\n",
       "      <td>10397</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>(400, 500]</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057389</th>\n",
       "      <td>1384262</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8671D</td>\n",
       "      <td>1189</td>\n",
       "      <td>15304</td>\n",
       "      <td>10397</td>\n",
       "      <td>1620</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>(400, 500]</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057390</th>\n",
       "      <td>1384263</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>WN</td>\n",
       "      <td>N942WN</td>\n",
       "      <td>2568</td>\n",
       "      <td>15304</td>\n",
       "      <td>10397</td>\n",
       "      <td>1320</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>(400, 500]</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1057391 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  month  day_of_month  day_of_week op_unique_carrier tail_num  \\\n",
       "0              0      1             5            6                DL    N3752   \n",
       "1              1      1             5            6                DL    N3752   \n",
       "2              2      1            26            6                AS   N282AK   \n",
       "3              3      1            26            6                AS   N307AS   \n",
       "4              4      1            26            6                AS   N318AS   \n",
       "...          ...    ...           ...          ...               ...      ...   \n",
       "1057386  1384259     12            30            1                WN   N413WN   \n",
       "1057387  1384260     12            30            1                WN   N742SW   \n",
       "1057388  1384261     12            30            1                WN   N774SW   \n",
       "1057389  1384262     12            30            1                WN   N8671D   \n",
       "1057390  1384263     12            30            1                WN   N942WN   \n",
       "\n",
       "         op_carrier_fl_num  origin_airport_id  dest_airport_id  crs_dep_time  \\\n",
       "0                     1901              10299            14747          1548   \n",
       "1                     2020              10299            14747           600   \n",
       "2                       52              10299            14747          1450   \n",
       "3                       88              10299            14747           600   \n",
       "4                       92              10299            14747          1305   \n",
       "...                    ...                ...              ...           ...   \n",
       "1057386                225              15304            10397          1005   \n",
       "1057387                758              15304            10397          1950   \n",
       "1057388                877              15304            10397           600   \n",
       "1057389               1189              15304            10397          1620   \n",
       "1057390               2568              15304            10397          1320   \n",
       "\n",
       "         ...  nas_delay  security_delay late_aircraft_delay  year  is_delayed  \\\n",
       "0        ...        NaN             NaN                 NaN  2019       False   \n",
       "1        ...       22.0             0.0                 0.0  2019       False   \n",
       "2        ...        NaN             NaN                 NaN  2019       False   \n",
       "3        ...        NaN             NaN                 NaN  2019       False   \n",
       "4        ...        NaN             NaN                 NaN  2019       False   \n",
       "...      ...        ...             ...                 ...   ...         ...   \n",
       "1057386  ...        NaN             NaN                 NaN  2019        True   \n",
       "1057387  ...        NaN             NaN                 NaN  2019       False   \n",
       "1057388  ...        NaN             NaN                 NaN  2019       False   \n",
       "1057389  ...        NaN             NaN                 NaN  2019       False   \n",
       "1057390  ...        NaN             NaN                 NaN  2019       False   \n",
       "\n",
       "         is_weekend  distance_agg  manufacture_year  origin_city_name  \\\n",
       "0             False  (1400, 1500]            2001.0     Anchorage, AK   \n",
       "1             False  (1400, 1500]            2001.0     Anchorage, AK   \n",
       "2             False  (1400, 1500]            2017.0     Anchorage, AK   \n",
       "3             False  (1400, 1500]            2001.0     Anchorage, AK   \n",
       "4             False  (1400, 1500]            2003.0     Anchorage, AK   \n",
       "...             ...           ...               ...               ...   \n",
       "1057386        True    (400, 500]            2001.0         Tampa, FL   \n",
       "1057387        True    (400, 500]            1998.0         Tampa, FL   \n",
       "1057388        True    (400, 500]            2000.0         Tampa, FL   \n",
       "1057389        True    (400, 500]            2015.0         Tampa, FL   \n",
       "1057390        True    (400, 500]            2009.0         Tampa, FL   \n",
       "\n",
       "         destination_city_name  \n",
       "0                  Seattle, WA  \n",
       "1                  Seattle, WA  \n",
       "2                  Seattle, WA  \n",
       "3                  Seattle, WA  \n",
       "4                  Seattle, WA  \n",
       "...                        ...  \n",
       "1057386            Atlanta, GA  \n",
       "1057387            Atlanta, GA  \n",
       "1057388            Atlanta, GA  \n",
       "1057389            Atlanta, GA  \n",
       "1057390            Atlanta, GA  \n",
       "\n",
       "[1057391 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dokonaj jeszcze raz złączenia ramki flight_df z airport_list_df, \n",
    "# tym razem jednak złącz kolumnę destination_airport_id wraz z origin_airport_id. \n",
    "# Podobnie jak wcześniej, interesuje nas kolumna origin_city_name, \n",
    "# jedank ona powinna zostać wyświetlona jako destination_city_name\n",
    "\n",
    "# Merge the DataFrames based on 'dest_airport_id' and 'origin_airport_id'\n",
    "merged_df = tmp_flight_df.merge(airport_list_df[['origin_airport_id', 'origin_city_name']], \n",
    "                                left_on='dest_airport_id', \n",
    "                                right_on='origin_airport_id', \n",
    "                                how='left')\n",
    "\n",
    "# Rename the 'origin_city_name_y' column to 'destination_city_name'\n",
    "merged_df = merged_df.rename(columns={'origin_city_name_y': 'destination_city_name', \n",
    "                                      'origin_airport_id_x': 'origin_airport_id', \n",
    "                                      'origin_city_name_x' : 'origin_city_name'})\n",
    "\n",
    "merged_df = merged_df.drop('origin_airport_id_y', axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flight_df = merged_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie\n",
    "Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert 'origin_city_name' in flight_df.columns, 'Brak kolumny `origin_city_name` w ramce flight_df'\n",
    "assert 'destination_city_name' in flight_df.columns, 'Brak kolumny `destination_city_name` w ramce flight_df'\n",
    "\n",
    "flight_df_expected_rows_amount = 1057391\n",
    "assert flight_df.shape[0] == flight_df_expected_rows_amount, 'Ups, zmieniła się liczba wierszy...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Analiza według lotnisk oraz tras\n",
    " Wykonaj poniższe polecenia:  \n",
    " 1. Wyznacz lotniska, z których **odlatywało** najwięcej samolotów. Wynik zapisz do ramki `top_airports_origin_df`.\n",
    " 1. Wyznacz lotnika, na których najwięcej lotów **się kończyło**. Wynik zapisz do ramki `top_airports_destination_df`.  \n",
    " 1. Wyznacz najczęściej uczęszczaną trasę, wynik zapisz do ramki `top_route_df`.  \n",
    " 1. Przy założeniu, że reprezentatywna liczba lotów na trasie wynosi ponad 500, wyznacz dodatkowo top 10:  \n",
    "     - tras z **najmniejszym odsetkiem opóźnień**, wynik zapisz do ramki `least_route_delays_df`.  \n",
    "     - tras z **największym odsetkiem opóźnień**, wynik zapisz do ramki `top_route_delays_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj wyznacz ramkę `top_airports_origin_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>year</th>\n",
       "      <th>is_delayed</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>distance_agg</th>\n",
       "      <th>manufacture_year</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>destination_city_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3752</td>\n",
       "      <td>1901</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1548</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3752</td>\n",
       "      <td>2020</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N282AK</td>\n",
       "      <td>52</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1450</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N307AS</td>\n",
       "      <td>88</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N318AS</td>\n",
       "      <td>92</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1305</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  month  day_of_month  day_of_week op_unique_carrier tail_num  \\\n",
       "0   0      1             5            6                DL    N3752   \n",
       "1   1      1             5            6                DL    N3752   \n",
       "2   2      1            26            6                AS   N282AK   \n",
       "3   3      1            26            6                AS   N307AS   \n",
       "4   4      1            26            6                AS   N318AS   \n",
       "\n",
       "   op_carrier_fl_num  origin_airport_id  dest_airport_id  crs_dep_time  ...  \\\n",
       "0               1901              10299            14747          1548  ...   \n",
       "1               2020              10299            14747           600  ...   \n",
       "2                 52              10299            14747          1450  ...   \n",
       "3                 88              10299            14747           600  ...   \n",
       "4                 92              10299            14747          1305  ...   \n",
       "\n",
       "   nas_delay  security_delay late_aircraft_delay  year  is_delayed  \\\n",
       "0        NaN             NaN                 NaN  2019       False   \n",
       "1       22.0             0.0                 0.0  2019       False   \n",
       "2        NaN             NaN                 NaN  2019       False   \n",
       "3        NaN             NaN                 NaN  2019       False   \n",
       "4        NaN             NaN                 NaN  2019       False   \n",
       "\n",
       "   is_weekend  distance_agg  manufacture_year  origin_city_name  \\\n",
       "0       False  (1400, 1500]            2001.0     Anchorage, AK   \n",
       "1       False  (1400, 1500]            2001.0     Anchorage, AK   \n",
       "2       False  (1400, 1500]            2017.0     Anchorage, AK   \n",
       "3       False  (1400, 1500]            2001.0     Anchorage, AK   \n",
       "4       False  (1400, 1500]            2003.0     Anchorage, AK   \n",
       "\n",
       "   destination_city_name  \n",
       "0            Seattle, WA  \n",
       "1            Seattle, WA  \n",
       "2            Seattle, WA  \n",
       "3            Seattle, WA  \n",
       "4            Seattle, WA  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10397</td>\n",
       "      <td>123162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13930</td>\n",
       "      <td>105437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12892</td>\n",
       "      <td>87849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11292</td>\n",
       "      <td>64525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12953</td>\n",
       "      <td>57708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10721</td>\n",
       "      <td>55989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14747</td>\n",
       "      <td>50465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14771</td>\n",
       "      <td>50124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11298</td>\n",
       "      <td>39511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12889</td>\n",
       "      <td>38456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin_airport_id  op_carrier_fl_num\n",
       "0              10397             123162\n",
       "1              13930             105437\n",
       "2              12892              87849\n",
       "3              11292              64525\n",
       "4              12953              57708\n",
       "5              10721              55989\n",
       "6              14747              50465\n",
       "7              14771              50124\n",
       "8              11298              39511\n",
       "9              12889              38456"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group origin airport id by count of op_carrier_fl\n",
    "top_airports_origin_df = flight_df.groupby('origin_airport_id')['op_carrier_fl_num'].count().reset_index()\n",
    "\n",
    "top_airports_origin_df = top_airports_origin_df.sort_values(by='op_carrier_fl_num', ascending=False).head(10).reset_index(drop=True)\n",
    "\n",
    "top_airports_origin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj wyznacz ramkę `top_airports_destination_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10397</td>\n",
       "      <td>122945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13930</td>\n",
       "      <td>100333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12892</td>\n",
       "      <td>87776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11292</td>\n",
       "      <td>64602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12953</td>\n",
       "      <td>57686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10721</td>\n",
       "      <td>56057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14747</td>\n",
       "      <td>50230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14771</td>\n",
       "      <td>49999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11298</td>\n",
       "      <td>39488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12889</td>\n",
       "      <td>38494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dest_airport_id  op_carrier_fl_num\n",
       "0            10397             122945\n",
       "1            13930             100333\n",
       "2            12892              87776\n",
       "3            11292              64602\n",
       "4            12953              57686\n",
       "5            10721              56057\n",
       "6            14747              50230\n",
       "7            14771              49999\n",
       "8            11298              39488\n",
       "9            12889              38494"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group origin airport id by count of op_carrier_fl\n",
    "top_airports_destination_df = flight_df.groupby('dest_airport_id')['op_carrier_fl_num'].count().reset_index()\n",
    "\n",
    "top_airports_destination_df = top_airports_destination_df.sort_values(by='op_carrier_fl_num', ascending=False).head(10).reset_index(drop=True)\n",
    "\n",
    "top_airports_destination_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Sprawdzenie dla `top_airport_origin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie dla `top_airport_destination`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_airports_destination_head = (top_airports_destination_df\n",
    "                                 .sort_values(by='op_carrier_fl_num', ascending=False) ##added by\n",
    "                                 .head()\n",
    "                                 ['op_carrier_fl_num'] ##added column name\n",
    "                                 .tolist() ##changed tolist() instead of to_list\n",
    "                                 )\n",
    "top_airports_destination_head = tuple(top_airports_destination_head)\n",
    "top_airports_destination_head_expected = (122945, 100333, 87776, 64602, 57686)\n",
    "\n",
    "assert top_airports_destination_head == top_airports_destination_head_expected, f\"Nie zgadza się top 5 wierszy, oczekiwano wyników: {top_airports_destination_head_expected} otrzymano: {top_airports_destination_head}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Wzbogacenie o dane pogodowe\n",
    " Używając procedury `read_sql_table`, wczytaj tabelę `airport_weather` do ramki `airport_weather_df`. Następnie wykonaj następujące polecenia:  \n",
    " 1. Pozostaw w ramce tylko następujące kolumny: `['station', 'name', 'date', 'prcp', 'snow', 'snwd', 'tmax', 'awnd']`.  \n",
    " 1. Połącz ramki `airport_list_df` wraz z `airport_weather_df` po odpowiedniej kolumnie używając takiego złączenia, aby w wyniku usunąć te wiersze (lotniska), które nie posiadają danych pogodowych. Dodatkowo, upewnij się, że zostanie tylko dodana kolumna `origin_airport_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj wczytaj ramkę `airport_weather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>awnd</th>\n",
       "      <th>pgtm</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "      <th>tavg</th>\n",
       "      <th>...</th>\n",
       "      <th>wt09</th>\n",
       "      <th>wesd</th>\n",
       "      <th>wt10</th>\n",
       "      <th>psun</th>\n",
       "      <th>tsun</th>\n",
       "      <th>sn32</th>\n",
       "      <th>sx32</th>\n",
       "      <th>tobs</th>\n",
       "      <th>wt11</th>\n",
       "      <th>wt18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>USW00013874</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>USW00013874</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>4.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>USW00013874</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>5.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>USW00013874</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>12.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>USW00013874</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>13.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      station                                               name  \\\n",
       "0   0  USW00013874  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...   \n",
       "1   1  USW00013874  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...   \n",
       "2   2  USW00013874  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...   \n",
       "3   3  USW00013874  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...   \n",
       "4   4  USW00013874  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...   \n",
       "\n",
       "         date   awnd  pgtm  prcp  snow  snwd  tavg  ...  wt09  wesd  wt10  \\\n",
       "0  2019-01-01   4.70   NaN  0.14   0.0   0.0  64.0  ...   NaN   NaN   NaN   \n",
       "1  2019-01-02   4.92   NaN  0.57   0.0   0.0  56.0  ...   NaN   NaN   NaN   \n",
       "2  2019-01-03   5.37   NaN  0.15   0.0   0.0  52.0  ...   NaN   NaN   NaN   \n",
       "3  2019-01-04  12.08   NaN  1.44   0.0   0.0  56.0  ...   NaN   NaN   NaN   \n",
       "4  2019-01-05  13.42   NaN  0.00   0.0   0.0  49.0  ...   NaN   NaN   NaN   \n",
       "\n",
       "   psun  tsun  sn32  sx32  tobs  wt11  wt18  \n",
       "0   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_weather_df = load_table_from_db('airport_weather')\n",
    "airport_weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj oczyść ramkę `airport_weather_df` z nadmiarowych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "      <th>tmax</th>\n",
       "      <th>awnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00013874</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00013874</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station                                               name        date  \\\n",
       "0  USW00013874  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...  2019-01-01   \n",
       "1  USW00013874  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...  2019-01-02   \n",
       "\n",
       "   prcp  snow  snwd  tmax  awnd  \n",
       "0  0.14   0.0   0.0  66.0  4.70  \n",
       "1  0.57   0.0   0.0  59.0  4.92  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_weather_df = airport_weather_df[['station', 'name', 'date', 'prcp', 'snow', 'snwd', 'tmax', 'awnd']]\n",
    "airport_weather_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj połącz ramki `airport_list_df` oraz `airport_weather_df` aktualizując `airport_weather_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>name</th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "      <th>tmax</th>\n",
       "      <th>awnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43389</th>\n",
       "      <td>10693</td>\n",
       "      <td>NORTH MYRTLE BEACH, SC US</td>\n",
       "      <td>USW00093718</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43390</th>\n",
       "      <td>10693</td>\n",
       "      <td>NORTH MYRTLE BEACH, SC US</td>\n",
       "      <td>USW00093718</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43391</th>\n",
       "      <td>10693</td>\n",
       "      <td>NORTH MYRTLE BEACH, SC US</td>\n",
       "      <td>USW00093718</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43392</th>\n",
       "      <td>10693</td>\n",
       "      <td>NORTH MYRTLE BEACH, SC US</td>\n",
       "      <td>USW00093718</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43393</th>\n",
       "      <td>10693</td>\n",
       "      <td>NORTH MYRTLE BEACH, SC US</td>\n",
       "      <td>USW00093718</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43394 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin_airport_id                                  name      station  \\\n",
       "0                  11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "1                  11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "2                  11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "3                  11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "4                  11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "...                  ...                                   ...          ...   \n",
       "43389              10693             NORTH MYRTLE BEACH, SC US  USW00093718   \n",
       "43390              10693             NORTH MYRTLE BEACH, SC US  USW00093718   \n",
       "43391              10693             NORTH MYRTLE BEACH, SC US  USW00093718   \n",
       "43392              10693             NORTH MYRTLE BEACH, SC US  USW00093718   \n",
       "43393              10693             NORTH MYRTLE BEACH, SC US  USW00093718   \n",
       "\n",
       "             date  prcp  snow  snwd  tmax   awnd  \n",
       "0      2019-01-01  0.00   0.0   0.0  50.0   3.13  \n",
       "1      2019-01-02  0.00   0.0   0.0  55.0   1.12  \n",
       "2      2019-01-03  0.00   0.0   0.0  59.0   2.01  \n",
       "3      2019-01-04  0.00   0.0   0.0  64.0   2.68  \n",
       "4      2019-01-05  0.30   0.0   0.0  57.0   7.38  \n",
       "...           ...   ...   ...   ...   ...    ...  \n",
       "43389  2020-03-27  0.00   NaN   NaN  75.0  12.30  \n",
       "43390  2020-03-28  0.00   NaN   NaN  77.0  13.87  \n",
       "43391  2020-03-29  0.00   NaN   NaN  80.0  13.87  \n",
       "43392  2020-03-30  0.00   NaN   NaN  80.0   5.82  \n",
       "43393  2020-03-31  0.55   NaN   NaN  67.0  10.51  \n",
       "\n",
       "[43394 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Połącz ramki airport_list_df wraz z airport_weather_df po odpowiedniej kolumnie używając takiego złączenia, \n",
    "# aby w wyniku usunąć te wiersze (lotniska), które nie posiadają danych pogodowych. \n",
    "# Dodatkowo, upewnij się, że zostanie tylko dodana kolumna origin_airport_id.\n",
    "\n",
    "airport_weather_df = pd.merge(airport_list_df[['origin_airport_id', 'name']], airport_weather_df, on='name', how='inner')\n",
    "airport_weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Sprawdzenie\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airport_weather_df_expected_shape = (43394, 9)\n",
    "airport_weather_df_shape = airport_weather_df.shape\n",
    "\n",
    "assert airport_weather_df_expected_shape == airport_weather_df_shape, \\\n",
    "  f'Nieodpowiedni wymiar ramki airport_weather_df, oczekiwano (wierszy, kolumn): {airport_weather_df_expected_shape}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Połączenie `airport_weather_df` oraz `flight_df`\n",
    " W celu złączenia ramek `airport_weather_df` oraz `flight_df` wykonaj następujące kroki:  \n",
    " 1. w ramce `aiport_weather_df` występuje kolumna `date`, zrzutuj ją na typ `DATETIME`.  \n",
    " 1. w ramce `flight_df` należy stworzyć nową kolumnę o nazwie `date`. W tym celu:  \n",
    " \t- złącz kolumny `month`, `day_of_month` oraz `year` razem, użyj następującego formatu daty: `YYYY-MM-DD`.\n",
    " \t- zrzutuj kolumnę `date` na typ `DATETIME`.  \n",
    " 1. złącz ramki używając odpowiedniego klucza, wynik złączenia zapisz do ramki `flight_df`. Użyj złącznia typu `LEFT JOIN`.\n",
    "\n",
    " > Dlaczego istotne jest zachowanie typów przy złączeniu?\n",
    "\n",
    "W trakcie pracy możesz posłużyć się następującymi artykułami z `LMS`:\n",
    " - `Python - analiza danych > Dzień 6 - Pandas > Merge`\n",
    " - `Python - analiza danych > Dzień 6 - Pandas > Praca z datetime`\n",
    " - Dokumentacje metody `to_datetime`: [klik](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)\n",
    " - Dostępne formaty dat: [klik](https://www.programiz.com/python-programming/datetime/strftime) - sekcja `Format Code List`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj zrzutuj kolumnę `date` na `DATETIME` w ramce `airport_weather_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_weather_df['date'] = pd.to_datetime(airport_weather_df['date'])\n",
    "type(airport_weather_df.loc[0, 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj stwórz kolumnę `date` w ramce `flight_df`. Pamiętaj, aby była ona również typu `DATETIME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>year</th>\n",
       "      <th>is_delayed</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>distance_agg</th>\n",
       "      <th>manufacture_year</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>destination_city_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3752</td>\n",
       "      <td>1901</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1548</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3752</td>\n",
       "      <td>2020</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N282AK</td>\n",
       "      <td>52</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1450</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>2019-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N307AS</td>\n",
       "      <td>88</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>2019-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AS</td>\n",
       "      <td>N318AS</td>\n",
       "      <td>92</td>\n",
       "      <td>10299</td>\n",
       "      <td>14747</td>\n",
       "      <td>1305</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1400, 1500]</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>2019-01-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  month  day_of_month  day_of_week op_unique_carrier tail_num  \\\n",
       "0   0      1             5            6                DL    N3752   \n",
       "1   1      1             5            6                DL    N3752   \n",
       "2   2      1            26            6                AS   N282AK   \n",
       "3   3      1            26            6                AS   N307AS   \n",
       "4   4      1            26            6                AS   N318AS   \n",
       "\n",
       "   op_carrier_fl_num  origin_airport_id  dest_airport_id  crs_dep_time  ...  \\\n",
       "0               1901              10299            14747          1548  ...   \n",
       "1               2020              10299            14747           600  ...   \n",
       "2                 52              10299            14747          1450  ...   \n",
       "3                 88              10299            14747           600  ...   \n",
       "4                 92              10299            14747          1305  ...   \n",
       "\n",
       "   security_delay  late_aircraft_delay  year  is_delayed  is_weekend  \\\n",
       "0             NaN                  NaN  2019       False       False   \n",
       "1             0.0                  0.0  2019       False       False   \n",
       "2             NaN                  NaN  2019       False       False   \n",
       "3             NaN                  NaN  2019       False       False   \n",
       "4             NaN                  NaN  2019       False       False   \n",
       "\n",
       "   distance_agg manufacture_year  origin_city_name  destination_city_name  \\\n",
       "0  (1400, 1500]           2001.0     Anchorage, AK            Seattle, WA   \n",
       "1  (1400, 1500]           2001.0     Anchorage, AK            Seattle, WA   \n",
       "2  (1400, 1500]           2017.0     Anchorage, AK            Seattle, WA   \n",
       "3  (1400, 1500]           2001.0     Anchorage, AK            Seattle, WA   \n",
       "4  (1400, 1500]           2003.0     Anchorage, AK            Seattle, WA   \n",
       "\n",
       "        date  \n",
       "0 2019-01-05  \n",
       "1 2019-01-05  \n",
       "2 2019-01-26  \n",
       "3 2019-01-26  \n",
       "4 2019-01-26  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w ramce flight_df należy stworzyć nową kolumnę o nazwie date. W tym celu:\n",
    "# złącz kolumny month, day_of_month oraz year razem, użyj następującego formatu daty: YYYY-MM-DD.\n",
    "# zrzutuj kolumnę date na typ DATETIME.\n",
    "\n",
    "flight_df['date'] = flight_df['year'].astype(str) + '-' + flight_df['month'].astype(str) + '-' + flight_df['day_of_month'].astype(str)\n",
    "flight_df['date'] = pd.to_datetime(flight_df['date'], format='%Y-%m-%d')\n",
    "flight_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>name</th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "      <th>tmax</th>\n",
       "      <th>awnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11638</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "      <td>USW00093193</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin_airport_id                                  name      station  \\\n",
       "0              11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "1              11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "2              11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "3              11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "4              11638  FRESNO YOSEMITE INTERNATIONAL, CA US  USW00093193   \n",
       "\n",
       "        date  prcp  snow  snwd  tmax  awnd  \n",
       "0 2019-01-01   0.0   0.0   0.0  50.0  3.13  \n",
       "1 2019-01-02   0.0   0.0   0.0  55.0  1.12  \n",
       "2 2019-01-03   0.0   0.0   0.0  59.0  2.01  \n",
       "3 2019-01-04   0.0   0.0   0.0  64.0  2.68  \n",
       "4 2019-01-05   0.3   0.0   0.0  57.0  7.38  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tutaj złącz tabeli `airport_weather_df` oraz `flight_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.53 GiB for an array with shape (473502716,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# złącz ramki używając odpowiedniego klucza, wynik złączenia zapisz do ramki flight_df. Użyj złącznia typu LEFT JOIN.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Dlaczego istotne jest zachowanie typów przy złączeniu?\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m merged \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflight_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mairport_weather_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morigin_airport_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m merged\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Kasia\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    148\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    149\u001b[0m         left,\n\u001b[0;32m    150\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kasia\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:809\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 809\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    812\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    813\u001b[0m )\n\u001b[0;32m    814\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\Users\\Kasia\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1065\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1062\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1063\u001b[0m     )\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1065\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Kasia\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1038\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_join_indexers\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]]:\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kasia\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1690\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[0;32m   1680\u001b[0m join_func \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m: libjoin\u001b[38;5;241m.\u001b[39minner_join,\n\u001b[0;32m   1682\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m: libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m: libjoin\u001b[38;5;241m.\u001b[39mfull_outer_join,\n\u001b[0;32m   1687\u001b[0m }[how]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;66;03m# error: Cannot call function of unknown type\u001b[39;00m\n\u001b[1;32m-> 1690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m join_func(lkey, rkey, count, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kasia\\anaconda3\\lib\\site-packages\\pandas\\_libs\\join.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.join.left_outer_join\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kasia\\anaconda3\\lib\\site-packages\\pandas\\_libs\\algos.pyx:238\u001b[0m, in \u001b[0;36mpandas._libs.algos.groupsort_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.53 GiB for an array with shape (473502716,) and data type int64"
     ]
    }
   ],
   "source": [
    "# złącz ramki używając odpowiedniego klucza, wynik złączenia zapisz do ramki flight_df. Użyj złącznia typu LEFT JOIN.\n",
    "# Dlaczego istotne jest zachowanie typów przy złączeniu?\n",
    "\n",
    "merged = pd.merge(flight_df, airport_weather_df, on='origin_airport_id', how= 'left')\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Sprawdzenie\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df_expected_rows_amount = 1057391\n",
    "assert flight_df.shape[0] == flight_df_expected_rows_amount, 'Ups, zmieniła się liczba wierszy...'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca samodzielna\n",
    "Używając `flight_df` zbadaj hipotezę o tym, że temperatura maksymalna wpływa na **odsetek** opóźnień lotów (kolumna `tmax`).  \n",
    "\n",
    "Przy wykonywaniu tego zadania masz pełną dowolność, jednak powinno składać się conajmniej z następujących elementów:\n",
    "- sprawdzenie, czy zmienna posiada obserwacje odstające,\n",
    "- oczyszczenie danych o ile konieczne,\n",
    "- przedstawienie w formie tabeli czy wzrost danej zmiennej powoduje zmianę w odsetku opóźnień lotów,\n",
    "- wizualizację stworzonej wcześniej tabeli w formie wykresu,\n",
    "- krótkiego opisu wyników w komórce markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Analiza dla kolumny `tmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miejsce na Twój komentarz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie\n",
    "W tej części warsztatu dokonaliśmy kompleksowej analizy posiadanego zbioru danych. Eksploracja\n",
    "pozwoliła nam na zapoznanie się z cechami charakterystycznymi lotów - wiemy już, które \n",
    "zmienne mogą mieć wpływ na opóźnienia lotów, a które nie. Co warto podkreślić, skupiliśmy się na wielu\n",
    "aspektach tej analizy, co otwiera potencjalnie również inne możliwości dalszej pracy nad tą bazą.\n",
    "\n",
    "W tym momencie przejdziemy do kolejnego kroku, w którym, na podstawie tej analizy, przygotujemy \n",
    "system raportowy. Zanim jednak stworzymy dashboard, potrzebujemy zaktualizować naszą bazę danych."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "38d75d0df746d7f75dd34c5d1915af59cb55786647bd68b8d9064425d7680b12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
