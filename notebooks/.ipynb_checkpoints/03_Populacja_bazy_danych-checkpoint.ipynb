{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Opis notatnika\n",
    " W poprzednich krokach pobraliśmy dane oraz przygotowaliśmy bazę `Postgres` na import. Głównym celem w tym notatniku jest  odpowiednie dostosowanie struktury danych z plików źródłowych do formatu zgodnego z `Postgres`, a następnie wgranie ich na nasz serwer. Dzięki temu w późniejszych krokach możemy niezależnie użyć danych do analizy czy raportowania.\n",
    " \n",
    " Ponownie wcielasz się w rolę Data Engineera, którego zadaniem jest zasilenie bay danych pobranymi danymi. Bez poprawnego załadowania danych nie będziesz w stanie dokonać analizy eksploracyjnej, która jest jednym z wymagań dostarczonych przez klienta.\n",
    "\n",
    " Przy wykonywaniu tego notebooka przydadzą się poniższe elementy kursu oraz materiały dodatkowe:\n",
    " * `SQL - analiza danych > Zjazd 1 - materiały dodatkowe > Export danych z DB > Python` - w celu użycia połączenia razem z `Pandas`,\n",
    " * https://docs.sqlalchemy.org/en/14/core/engines.html - w celu uzupełnienia konfiguracji `Pandas` do `PostgerSQL`,\n",
    " * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html - eksport danych z `Pandas` na bazę danych.\n",
    "\n",
    " > Uwaga: Ze względu na wolumen danych zawarty w pliku `flight.csv`, wykonanie tego notatnika może zająć nawet kilkadziesiąt minut lub więcej!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Połączenie z bazą danych\n",
    "Tutaj uzupełnij konfigurację połączenia tworząc zmienne takie jak:\n",
    "- `username` - nazwa użytkownika bazy,\n",
    "- `password` - hasło do bazy,\n",
    "- `host` - adres naszej bazy danych, jeśli baza jest postawiona na naszej maszynie wtedy będzie to po prostu `localhost`,\n",
    "- `database` - nazwa bazy danych np. `postgresql`\n",
    "- `port` - domyślnie `5432`\n",
    "\n",
    "> Przetrzymywanie hasła w ten sposób nie jest bezpieczne, co było zaznaczane w trakcie kursu. Lepszym sposobem jest używanie zmiennych środowiskowych, ale na nasze potrzeby nie jest to potrzebne. Dla osób chcących zapoznać się z taką formą zalecamy ten artykuł - [klik](https://developer.vonage.com/blog/21/10/01/python-environment-variables-a-primer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-2.0.22-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "                                              0.0/2.1 MB ? eta -:--:--\n",
      "     -                                        0.1/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "     ---                                      0.2/2.1 MB 2.5 MB/s eta 0:00:01\n",
      "     -------                                  0.4/2.1 MB 3.2 MB/s eta 0:00:01\n",
      "     -----------                              0.6/2.1 MB 3.4 MB/s eta 0:00:01\n",
      "     ----------------                         0.9/2.1 MB 3.6 MB/s eta 0:00:01\n",
      "     --------------------                     1.1/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------                1.3/2.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------             1.5/2.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------        1.7/2.1 MB 4.2 MB/s eta 0:00:01\n",
      "     -----------------------------------      1.8/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.1 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\kasia\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.6.3)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Downloading greenlet-3.0.0-cp310-cp310-win_amd64.whl (287 kB)\n",
      "                                              0.0/287.7 kB ? eta -:--:--\n",
      "     --------------------------------       245.8/287.7 kB 7.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  286.7/287.7 kB 5.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  286.7/287.7 kB 5.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  286.7/287.7 kB 5.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 287.7/287.7 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.0.0 sqlalchemy-2.0.22\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\kasia\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\kasia\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -fi (c:\\users\\kasia\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\kasia\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\kasia\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -fi (c:\\users\\kasia\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from psycopg2 import connect\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'postgres'\n",
    "password = 'qpa102188523'\n",
    "\n",
    "host = 'localhost'\n",
    "database = 'airlines'\n",
    "port = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Z pomocą artykułu [click](https://docs.sqlalchemy.org/en/14/core/engines.html) stwórz zmienne `url` oraz `engine`. Zgodnie z dokumentacją `Pandas`, zmienna `engine` będzie potrzebna, by móc wyeksportować dane na serwer `SQL`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym miejscu stwórz zmienne `url` oraz `engine`\n",
    "> Wskazówka: Zmienna `url` powinna być stworzona zgodnie ze schematem jak we wcześniej podanym artykule, jednak powinna używać zmiennych zdefiniowanych wyżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_object = URL.create(\n",
    "    \"postgresql\",\n",
    "    username = 'postgres',\n",
    "    password = 'qpa102188523',\n",
    "    host = 'localhost',\n",
    "    database = 'airlines')\n",
    "    \n",
    "engine = create_engine(url_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Załadowanie ramek do obszaru roboczego\n",
    " Uzupełnij implementacje funkcji `load_raw_data`, która przyjmuje jeden parametr:\n",
    " * `file_name` - nazwa pliku do zaczytania\n",
    " Jej zadaniem jest wczytanie surowego pliku, zmodyfikowanie nazw kolumn z `NAZWA_KOLUMNY` na `nazwa_kolumny` oraz zwrócenie tak zmodyfikowanej ramki danych\n",
    "\n",
    " Mogą się przydać poniższe element kursu:\n",
    " - `Python-Analiza danych -> Dzień 5 - Pandas -> Obróbka danych - częsć 1`\n",
    " - `Python-Analiza danych -> Przygotowanie do zjazdu 3 -> Wstęp do Pandas -> Wczytywanie danych do Pandas` - jakie kodowanie mają pliki?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(file_name):\n",
    "    df = pd.read_csv(file_name, encoding='UTF-8')\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Zaczytanie poszczególnych plików do ramek\n",
    "\n",
    " W tym miejscu zaczytaj poszczególne pliki do ramek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft_df = load_raw_data(r'..\\data\\raw\\aircraft.csv')\n",
    "airport_weather_df = load_raw_data(r'..\\data\\raw\\airport_weather.csv')\n",
    "flight_df = load_raw_data(r'..\\data\\raw\\flight.csv')\n",
    "airport_list_df = load_raw_data(r'..\\data\\raw\\airport_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>display_airport_name</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11638</td>\n",
       "      <td>Fresno Air Terminal</td>\n",
       "      <td>Fresno, CA</td>\n",
       "      <td>FRESNO YOSEMITE INTERNATIONAL, CA US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13342</td>\n",
       "      <td>General Mitchell Field</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>MILWAUKEE MITCHELL AIRPORT, WI US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13244</td>\n",
       "      <td>Memphis International</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>MEMPHIS INTERNATIONAL AIRPORT, TN US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15096</td>\n",
       "      <td>Syracuse Hancock International</td>\n",
       "      <td>Syracuse, NY</td>\n",
       "      <td>SYRACUSE HANCOCK INTERNATIONAL AIRPORT, NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10397</td>\n",
       "      <td>Atlanta Municipal</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10529</td>\n",
       "      <td>Bradley International</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>HARTFORD BRADLEY INTERNATIONAL AIRPORT, CT US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10140</td>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>ALBUQUERQUE INTERNATIONAL AIRPORT, NM US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10792</td>\n",
       "      <td>Greater Buffalo International</td>\n",
       "      <td>Buffalo, NY</td>\n",
       "      <td>BUFFALO NIAGARA INTERNATIONAL, NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10599</td>\n",
       "      <td>Birmingham Airport</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>BIRMINGHAM AIRPORT, AL US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14831</td>\n",
       "      <td>San Jose International</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>SAN JOSE INTERNATIONAL AIRPORT, CA US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin_airport_id               display_airport_name origin_city_name  \\\n",
       "0              11638                Fresno Air Terminal       Fresno, CA   \n",
       "1              13342             General Mitchell Field    Milwaukee, WI   \n",
       "2              13244              Memphis International      Memphis, TN   \n",
       "3              15096     Syracuse Hancock International     Syracuse, NY   \n",
       "4              10397                  Atlanta Municipal      Atlanta, GA   \n",
       "5              10529              Bradley International     Hartford, CT   \n",
       "6              10140  Albuquerque International Sunport  Albuquerque, NM   \n",
       "7              10792      Greater Buffalo International      Buffalo, NY   \n",
       "8              10599                 Birmingham Airport   Birmingham, AL   \n",
       "9              14831             San Jose International     San Jose, CA   \n",
       "\n",
       "                                                name  \n",
       "0               FRESNO YOSEMITE INTERNATIONAL, CA US  \n",
       "1                  MILWAUKEE MITCHELL AIRPORT, WI US  \n",
       "2               MEMPHIS INTERNATIONAL AIRPORT, TN US  \n",
       "3      SYRACUSE HANCOCK INTERNATIONAL AIRPORT, NY US  \n",
       "4  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...  \n",
       "5      HARTFORD BRADLEY INTERNATIONAL AIRPORT, CT US  \n",
       "6           ALBUQUERQUE INTERNATIONAL AIRPORT, NM US  \n",
       "7               BUFFALO NIAGARA INTERNATIONAL, NY US  \n",
       "8                          BIRMINGHAM AIRPORT, AL US  \n",
       "9              SAN JOSE INTERNATIONAL AIRPORT, CA US  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_list_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Eksport danych na bazę\n",
    " Zapoznaj się z dokumentacją metody `Pandas` - [to_sql](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html), której zadaniem jest wyeksportowanie ramki na bazę danych.\n",
    " Zwróć szczególną uwagę na poniższe parametry:\n",
    " * `if_exists` - jak ma się zachować metoda, gdy ładuje dane na bazę,\n",
    " * `con` - połączenie do bazy,\n",
    " * `name` - nazwa tabeli, do której ramka ma zostać wgrana,\n",
    " * `index` - czy dodawać index z ramki jako kolumnę,\n",
    " * `chunksize` - maksymalna liczba wierszy wgrywana za jednym razem.\n",
    "\n",
    " > **Uwaga:** \n",
    " > Przed eksportem upewnij się, że tabela jest pusta. Zwróć uwagę na pewną subtelną różnicę pomiędzy wyglądem ramki oraz tabeli docelowej na bazie danych.\n",
    "\n",
    "Następnie uzupełnij implementację metody `export_table_to_db`, która przyjmuje dwa argumenty:\n",
    " * `df` - ramka danych do eksportu,\n",
    " * `table_name` - nazwa ramki na bazie.\n",
    "\n",
    "Zalecamy, aby dodać do metody informację, która ramka jest aktualnie ładowana np.:\n",
    " `Loading data into {table_name}...`\n",
    " > Ze względu na rozmiar ramki `flight_df`, proces ten może potrwać nawet kilkadziesiąt minut! Z tego względu, na potrzeby testów, zalecamy przekazanie do procedury `export_table_to_db` np. pierwszych 5 wierszy, aby sprawdzić, czy działa, a potem wgrać cały zestaw danych - pamiętając o upszednim usunięciu tamtych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_table_to_db(df, table_name):\n",
    "    connection = engine.raw_connection()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(f'TRUNCATE TABLE {table_name};') #clear the table before inserting data (in case of multiple code execution)\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    df.to_sql(name=table_name, \n",
    "              con=engine, \n",
    "              if_exists='append', \n",
    "              index=True, \n",
    "              index_label='id', \n",
    "              chunksize=5000, \n",
    "              method=None) #‘multi’: Pass multiple values in a single INSERT clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Wgrywanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Wgranie `aircraft_df` do tabeli `aircraft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_to_db(aircraft_df, 'aircraft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Wgranie `airport_weather_df` do tabeli `airport_weather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_to_db(airport_weather_df, 'airport_weather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Wgranie `flight_df` do tabeli `flight`\n",
    " > Wykonanie tej komórki może zająć kilka-kilknaście minut za względu na ilość danych w ramce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_to_db(flight_df, 'flight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Wgranie `airport_list_df` do tabeli `airport_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_table_to_db(airport_list_df, 'airport_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Sprawdzenie poprawności wykonania notatnika\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_export(table_name, expected_count, expected_schema):\n",
    "    real_count = pd.read_sql(f\"SELECT COUNT(*) as cnt FROM {table_name}\", engine).iloc[0][0]\n",
    "    \n",
    "    real_schema = pd.read_sql(f\"SELECT * FROM {table_name} LIMIT 0\", engine)\n",
    "    real_schema = set(real_schema.columns)\n",
    "\n",
    "    expected_schema = set(expected_schema)\n",
    "\n",
    "    diff = real_schema.symmetric_difference(expected_schema)\n",
    "\n",
    "    assert len(diff) == 0, ('Nie zgadzają się kolumny tabel....'\n",
    "    f'\\tOczekiwano: {expected_schema}'\n",
    "    f'\\tOtrzymano: {real_schema}'\n",
    "    f'\\tRóżnica: {diff}')\n",
    "\n",
    "    assert expected_count == real_count, \\\n",
    "        f'Nie zgadza się liczba wierszy, oczekiwano {expected_count}, otrzymano {real_count} - sprawdź, czy nie dane nie zostały wgrane do tabeli \"{table_name}\" więcej niż raz.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sprawdzenie tabeli `aircraft`\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft_expected_count = 7383\n",
    "aircraft_expected_schema = ['id', 'manufacture_year', 'tail_num', 'number_of_seats']\n",
    "\n",
    "test_data_export('aircraft', aircraft_expected_count, aircraft_expected_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sprawdzenie tabeli `airport_weather`\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_weather_expected_count = 46226\n",
    "airport_weather_expected_schema = [\n",
    "       'id', 'station', 'name', 'date', 'awnd', 'prcp', 'snow', 'snwd', 'tavg', \n",
    "       'tmax', 'tmin', 'wdf2', 'wdf5', 'wsf2', 'wsf5', 'wt01', 'wt08', 'wt02',\n",
    "       'wt03', 'wt04', 'wt09', 'wt06', 'wt05', 'pgtm', 'wt10', 'wesd', 'sn32',\n",
    "       'sx32', 'psun', 'tsun', 'tobs', 'wt07', 'wt11', 'wt18']\n",
    "\n",
    "test_data_export('airport_weather', airport_weather_expected_count, airport_weather_expected_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sprawdzenie tabeli `flight`\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_expected_count = 1386120\n",
    "flight_expected_schema = [\n",
    "       'id', 'month', 'day_of_month', 'day_of_week', 'op_unique_carrier', 'tail_num',\n",
    "       'op_carrier_fl_num', 'origin_airport_id', 'dest_airport_id',\n",
    "       'crs_dep_time', 'dep_time', 'dep_delay_new', 'dep_time_blk',\n",
    "       'crs_arr_time', 'arr_time', 'arr_delay_new', 'arr_time_blk',\n",
    "       'cancelled', 'crs_elapsed_time', 'actual_elapsed_time', 'distance',\n",
    "       'distance_group', 'year', 'carrier_delay', 'weather_delay', 'nas_delay',\n",
    "       'security_delay', 'late_aircraft_delay']\n",
    "\n",
    "test_data_export('flight', flight_expected_count, flight_expected_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sprawdzenie tabeli `airport_list`\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_list_expected_count = 97\n",
    "airport_list_expected_schema = ['id', 'origin_airport_id', 'display_airport_name', 'origin_city_name', 'name']\n",
    "\n",
    "test_data_export('airport_list', airport_list_expected_count, airport_list_expected_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wszystko wygląda OK :) Możesz przejść do kolejnego kroku.\n"
     ]
    }
   ],
   "source": [
    "msg = \"Wszystko wygląda OK :) Możesz przejść do kolejnego kroku.\"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Podsumowanie\n",
    " W tym notatniku załadowaliśmy pobrane wcześniej pliki na bazę danych. Dzięki temu stworzyliśmy centralne miejsce ich magazynowania, co wykorzystamy zarówno przy analizie danych, jak i przy późniejszej budowie systemu raportowego."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "38d75d0df746d7f75dd34c5d1915af59cb55786647bd68b8d9064425d7680b12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
